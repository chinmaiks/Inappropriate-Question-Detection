{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AML_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yjIkuN0HrPms"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TcbYRTCVFFOQ",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, MaxPooling1D, Concatenate, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKeotuI2FSIO",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "maOxQTLasN5h"
      },
      "source": [
        "# Reading Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6hQqVribFgAo",
        "colab": {}
      },
      "source": [
        "base_path = \"/gdrive/My Drive/MS/AML/data/\" #as per individual folder paths\n",
        "# base_path = \"C:/Users/ckaidab/Documents/AML/data/\"\n",
        "training_file = \"train.csv\"\n",
        "testing_file = \"test.csv\"\n",
        "\n",
        "glove_embeddings = \"glove.6B.100d.txt\"\n",
        "\n",
        "test_labels = \"test_labels.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xu3F75gFFFOb",
        "colab": {}
      },
      "source": [
        "trainDf1 = pd.read_csv(base_path + training_file)\n",
        "testDf1 = pd.read_csv(base_path + testing_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8wnlH-oKAR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDf = trainDf1.head(trainDf1.shape[0]//2)\n",
        "testDf = testDf1.head(10000)\n",
        "trainDf.shape, testDf.shape, trainDf1.shape, testDf1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p4hUY5WrFFOj",
        "colab": {}
      },
      "source": [
        "trainDf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QRn8VwgGsUt1"
      },
      "source": [
        "# Flagging the comments as inappropriate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l1wJPBdmFFOw",
        "outputId": "69db3db3-b6c4-4af4-806a-8846dcdc4416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def isToxic(row):\n",
        "    \"\"\"Comments which are toxic, obscene, a threat, an insult and has identity hate are marked as inappropriate\"\"\"\n",
        "    if row[\"toxic\"] == 1 or row[\"severe_toxic\"] == 1 or row[\"obscene\"] == 1 or row[\"threat\"] == 1 or row[\"insult\"] ==1 or row[\"identity_hate\"] == 1:\n",
        "        return 1\n",
        "    return 0\n",
        "trainDf[\"inappropriate\"] = trainDf.apply(lambda x: isToxic(x), axis=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X5N9tgMvFFO6",
        "colab": {}
      },
      "source": [
        "columns = [\"id\", \"comment_text\", \"inappropriate\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SmBeWERMFFPA",
        "colab": {}
      },
      "source": [
        "trainDf = trainDf[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U53qAPiXKASI",
        "colab_type": "code",
        "outputId": "c43f6a75-65ff-4536-ed01-6c407da460b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDf.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79785, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mRXHA1T-smOs"
      },
      "source": [
        "# Tokenizing the text and converting to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omRvTTkYFFPH",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(trainDf[\"comment_text\"])\n",
        "encoded = tokenizer.texts_to_sequences(trainDf[\"comment_text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lII_3OsgFFPP",
        "colab": {}
      },
      "source": [
        "avg_len = 0;\n",
        "for i in range(0, len(encoded)):\n",
        "    avg_len += len(encoded[i])\n",
        "\n",
        "avg_len = avg_len // len(encoded)\n",
        "print(\"Avg length of sequences is: {}\".format(avg_len))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(\"Vocab size is:{}\".format(vocab_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fdsaaRKcFFPV",
        "colab": {}
      },
      "source": [
        "padded_docs = pad_sequences(encoded, maxlen=avg_len, padding='post')\n",
        "X_train, X_val, Y_train, Y_val = train_test_split( padded_docs, trainDf[\"inappropriate\"], test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvDPQhNkKASX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYxKxcrnxDYw"
      },
      "source": [
        "# Getting Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BmoFID-ZFFPa",
        "colab": {}
      },
      "source": [
        "word_to_embedding = dict()\n",
        "f = open(base_path + glove_embeddings, \"rb\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_to_embedding[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R5Zj5ob9FFPf",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = word_to_embedding.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X_CjCaHLxynN",
        "colab": {}
      },
      "source": [
        "earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y8TWNRhpwouE"
      },
      "source": [
        "# CNN Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YytcdrNhwmw_",
        "colab": {}
      },
      "source": [
        "def getCNN():\n",
        "  input_seq = Input(shape=(avg_len,), dtype='int32')\n",
        "  embedding = Embedding(vocab_size, 100, weights=[embedding_matrix], \n",
        "                            input_length=avg_len, trainable=True)(input_seq)\n",
        "\n",
        "  conv = Conv1D(64, kernel_size=2, padding='same', activation='relu', strides=1)(embedding)\n",
        "  pool = MaxPooling1D(pool_size=3)(conv)\n",
        "  drop1 = Dropout(0.5)(pool)\n",
        "  \n",
        "  conv = Conv1D(256, kernel_size=4, padding='same', activation='relu', strides=1)(embedding)\n",
        "  pool = MaxPooling1D(pool_size=3)(conv)\n",
        "  drop2 = Dropout(0.5)(pool)\n",
        "\n",
        "  merged = Concatenate()([drop1, drop2])\n",
        "  flatten = Flatten()(merged)\n",
        "  drop = Dropout(0.5)(flatten)\n",
        "  outp = Dense(1, activation='sigmoid')(drop)\n",
        "\n",
        "  cnnModel = Model(inputs=input_seq, outputs=outp)\n",
        "  cnnModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return cnnModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rX-S_VGGxBU1",
        "colab": {}
      },
      "source": [
        "cnnModel = getCNN()\n",
        "print(cnnModel.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kvvt9A6Jxtzu",
        "colab": {}
      },
      "source": [
        "fittedModel_cnn = cnnModel.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=256, verbose=True, callbacks=[earlyStopping])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9v5MuTkKASv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(fittedModel_cnn.history['accuracy'])\n",
        "plt.plot(fittedModel_cnn.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'val'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(fittedModel_cnn.history['loss'])\n",
        "plt.plot(fittedModel_cnn.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WSJFQXOHyZ8o"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KVki2XG5FFPs",
        "colab": {}
      },
      "source": [
        "def get_LSTM():\n",
        "    input_seq = Input(shape=(avg_len,))\n",
        "    embedding = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=avg_len, trainable=True)(input_seq)\n",
        "    x = LSTM(64, return_sequences=True)(embedding)\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    x = Dense(50, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(input_seq, x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kxZIXcWuFFPx",
        "colab": {}
      },
      "source": [
        "lstm_model = get_LSTM()\n",
        "lstm_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5bkra_2RFFP3",
        "colab": {}
      },
      "source": [
        "history_lstm = lstm_model.fit(X_train, Y_train, batch_size=512, epochs=10, verbose=1, validation_data=(X_val, Y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3W9g_2FKAS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_lstm.history['accuracy'])\n",
        "plt.plot(history_lstm.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'val'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_lstm.history['loss'])\n",
        "plt.plot(history_lstm.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l3154N43HAws",
        "colab": {}
      },
      "source": [
        "Y_test = pd.read_csv(base_path + test_labels)\n",
        "\n",
        "encoded_test = tokenizer.texts_to_sequences(testDf[\"comment_text\"])\n",
        "padded_docs_test = pad_sequences(encoded_test, maxlen=avg_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZP8qCsnhR5W1",
        "colab": {}
      },
      "source": [
        "predictions = cnnModel.predict(padded_docs_test[:1000], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i9TFgGtmNXGs",
        "colab": {}
      },
      "source": [
        "for i in range(len(predictions)):\n",
        "    if predictions[i]>0.5:\n",
        "        predictions[i] = 1\n",
        "    else:\n",
        "        predictions[i] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mph0UskKFFQQ",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kkji52agOaZq",
        "colab": {}
      },
      "source": [
        "Y_test[\"inappropriate\"] = Y_test.apply(lambda x: isToxic(x), axis=1)\n",
        "Y_test = Y_test[[\"id\", \"inappropriate\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-16E6G8oOkWM",
        "colab": {}
      },
      "source": [
        "Y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HtJgu7caPOmo",
        "colab": {}
      },
      "source": [
        "Y_test = [[int(i)] for i in Y_test[\"inappropriate\"].tolist()[:1000]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7-DljiQNeb-",
        "colab": {}
      },
      "source": [
        "print(classification_report(Y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i24ZOCHUNogc",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(\n",
        "   confusion_matrix(Y_test, predictions),\n",
        "   index = [['Actual', 'Actual'], ['Appropriate', 'Inappropriate']],\n",
        "   columns = [['Predicted', 'Predicted'], ['Appropiate', 'Inappropriate']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-WO15cdSgAo",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}